{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ho6VihwAkEn6"
   },
   "outputs": [],
   "source": [
    "#import required libraries after installing the packages from the Autosklearn_installation_guide.ipynb file\n",
    "\n",
    "import autosklearn\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import autosklearn.classification\n",
    "import autosklearn.classification as classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from autosklearn.classification import AutoSklearnClassifier\n",
    "from autosklearn.metrics import (accuracy,\n",
    "                                 f1,\n",
    "                                 roc_auc,\n",
    "                                 precision,\n",
    "                                 average_precision,\n",
    "                                 recall,\n",
    "                                 log_loss,\n",
    "                                 r2,\n",
    "                                 mean_squared_error,\n",
    "                                 mean_absolute_error,\n",
    "                                 )\n",
    "from sklearn.utils.fixes import _joblib_parallel_args\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load resistance data\n",
    "resistance_data = pd.read_excel('PA_phenotypes_(MIC).xlsx', index_col=0)\n",
    "\n",
    "resistance_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load expression data from Sheet 1, skipping the 2nd and 3rd rows visually in the Excel file\n",
    "expression = pd.read_excel('PA_Expression_data.xlsx', sheet_name=0, index_col=0, skiprows=None)\n",
    "\n",
    "# Delete columns 'PA14_1' and 'PA14_2' from the DataFrame\n",
    "expression = expression.drop(['PA14_1', 'PA14_2'], axis=1)\n",
    "\n",
    "# Display the DataFrame\n",
    "expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel file for the feature set identified using GA.\n",
    "file_path = 'Dataset_name' #For annotated feature sets follow Dataset EV6 and for iteration-specific feature sets, you can follow Dataset EV1\n",
    "\n",
    "# Read the Excel file, assuming the gene names are in the sheets and column A\n",
    "df = pd.read_excel(file_path, sheet_name=1, usecols=\"A\", header=None) #change sheet number according to the antibiotic and feature set.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all gene names\n",
    "Log_reg_acc_genes = df.iloc[:,0].tolist()\n",
    "\n",
    "# Select these genes from your expression DataFrame\n",
    "expression_red = expression.loc[Log_reg_acc_genes]\n",
    "expression_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression = expression_red.T.iloc[:, :]\n",
    "expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define X\n",
    "X = expression\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create y matrix\n",
    "y = resistance_data.reindex(X.index)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows with missing values for CAZ\n",
    "y_nonan = y.dropna(subset=[\"CAZ\"])\n",
    "y_nonan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X[X.index.isin(y_nonan.index)]\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create y_CAZ matrix to see fitting results for one drug type\n",
    "\n",
    "y_CAZ = y_nonan['CAZ']\n",
    "y_CAZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histogram to check distribution of MICs.\n",
    "hist, bins = np.histogram(y_CAZ, bins=2)\n",
    "\n",
    "print(\"Histogram:\", hist)\n",
    "print(\"Bins:\", bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y_CAZ, test_size = 0.2, random_state=1, stratify=y_CAZ)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "T0wORbvm_tXb"
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "clf = AutoSklearnClassifier(time_left_for_this_task=18000,\n",
    "                            #max_models_on_disc=5,\n",
    "                            memory_limit = 10240,\n",
    "                            resampling_strategy=skf,\n",
    "                            ensemble_kwargs={'ensemble_size': 3},\n",
    "                            metric=f1,\n",
    "                            scoring_functions=[roc_auc, average_precision, accuracy, f1, precision, recall, log_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X=X_train, y=y_train, X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.sprint_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_results = pd.DataFrame(clf.cv_results_).sort_values(by = 'mean_test_score', ascending = False)\n",
    "df_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_results.to_excel(\"AutoML_clf_run_results.xlsx\") # you can name the file according to the no. of features and antibiotic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.leaderboard(detailed = True, ensemble_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_leaderboard = pd.DataFrame(clf.leaderboard(detailed = True, ensemble_only=False))\n",
    "df_cv_leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_leaderboard.to_excel(\"AutoML_clf_run_leaderboard.xlsx.xlsx\") # you can name the file according to the no. of features and antibiotic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "joblib.dump(clf,'AutoML_clf_run_model.joblib') # you can name the file according to the no. of features and antibiotic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qL-20AQps1s"
   },
   "outputs": [],
   "source": [
    "#load the model\n",
    "clf2 = joblib.load('AutoML_clf_run_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nnZSyvEGp2Bs"
   },
   "outputs": [],
   "source": [
    "clf2.sprint_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eL5VbVRFqAsh"
   },
   "outputs": [],
   "source": [
    "clf2.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2.refit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fHHtvYpczmg"
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test = clf2.predict(X_test)\n",
    "print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#print classification report for model\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_hat_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get detailed information about feature preprocessor, classifier, and balancing strategy\n",
    "models = clf2.get_models_with_weights()\n",
    "\n",
    "for weight, model in models:\n",
    "    print(\"Weight:\", weight)\n",
    "    print(\"Model:\", model)\n",
    "    # Each component of the pipeline can be accessed like this:\n",
    "    print(\"Preprocessing steps:\", model.named_steps['data_preprocessor'])\n",
    "    print(\"Classifier:\", model.named_steps['classifier'])\n",
    "    # Balancing strategy (if any) will be part of preprocessing or classifier depending on the algorithm\n",
    "    if 'balancing' in model.named_steps:\n",
    "        print(\"Balancing strategy:\", model.named_steps['balancing'])\n",
    "    else:\n",
    "        print(\"None.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
